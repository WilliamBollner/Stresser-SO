//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30672275
// Cuda compilation tools, release 11.5, V11.5.119
// Based on NVVM 7.0.1
//

.version 7.5
.target sm_52
.address_size 64

	// .globl	stressKernel
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry stressKernel(
	.param .u64 stressKernel_param_0,
	.param .u32 stressKernel_param_1
)
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<33>;
	.reg .f32 	%f<97>;
	.reg .b32 	%r<163>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<77>;


	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd22, [stressKernel_param_0];
	ld.param.u32 	%r52, [stressKernel_param_1];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r53, %ntid.x;
	mov.u32 	%r54, %ctaid.x;
	mov.u32 	%r55, %tid.x;
	mad.lo.s32 	%r1, %r54, %r53, %r55;
	mov.u32 	%r56, %nctaid.x;
	mul.lo.s32 	%r57, %r53, %r56;
	setp.ge.u32 	%p1, %r1, %r57;
	@%p1 bra 	$L__BB0_37;

	cvta.to.global.u64 	%rd24, %rd22;
	mul.wide.s32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.f32 	%f96, [%rd26];
	setp.lt.s32 	%p2, %r52, 1;
	@%p2 bra 	$L__BB0_36;

	mov.u32 	%r152, 0;
	mov.f32 	%f33, 0fBFC90FDA;
	mov.f32 	%f35, 0fB3A22168;
	mov.f32 	%f37, 0fA7C234C5;
	mov.u64 	%rd28, 0;
	mov.u64 	%rd27, __cudart_i2opi_f;

$L__BB0_3:
	mul.f32 	%f31, %f96, 0f3F22F983;
	cvt.rni.s32.f32 	%r162, %f31;
	cvt.rn.f32.s32 	%f32, %r162;
	fma.rn.f32 	%f34, %f32, %f33, %f96;
	fma.rn.f32 	%f36, %f32, %f35, %f34;
	fma.rn.f32 	%f95, %f32, %f37, %f36;
	abs.f32 	%f4, %f96;
	setp.leu.f32 	%p3, %f4, 0f47CE4780;
	mov.u32 	%r156, %r162;
	mov.f32 	%f89, %f95;
	@%p3 bra 	$L__BB0_11;

	setp.eq.f32 	%p4, %f4, 0f7F800000;
	@%p4 bra 	$L__BB0_10;
	bra.uni 	$L__BB0_5;

$L__BB0_10:
	mov.f32 	%f40, 0f00000000;
	mul.rn.f32 	%f89, %f96, %f40;
	mov.u32 	%r156, %r162;
	bra.uni 	$L__BB0_11;

$L__BB0_5:
	mov.b32 	%r4, %f96;
	bfe.u32 	%r60, %r4, 23, 8;
	add.s32 	%r5, %r60, -128;
	shl.b32 	%r61, %r4, 8;
	or.b32  	%r6, %r61, -2147483648;
	shr.u32 	%r7, %r5, 5;
	mov.u32 	%r153, 0;
	mov.u64 	%rd68, %rd27;
	mov.u64 	%rd69, %rd1;
	mov.u64 	%rd70, %rd28;

$L__BB0_6:
	.pragma "nounroll";
	ld.global.nc.u32 	%r62, [%rd68];
	mad.wide.u32 	%rd29, %r62, %r6, %rd70;
	shr.u64 	%rd70, %rd29, 32;
	st.local.u32 	[%rd69], %rd29;
	add.s64 	%rd69, %rd69, 4;
	add.s64 	%rd68, %rd68, 4;
	add.s32 	%r153, %r153, 1;
	setp.ne.s32 	%p5, %r153, 6;
	@%p5 bra 	$L__BB0_6;

	st.local.u32 	[%rd1+24], %rd70;
	mov.u32 	%r63, 4;
	sub.s32 	%r10, %r63, %r7;
	mov.u32 	%r64, 6;
	sub.s32 	%r65, %r64, %r7;
	mul.wide.s32 	%rd30, %r65, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.local.u32 	%r154, [%rd31];
	ld.local.u32 	%r155, [%rd31+-4];
	and.b32  	%r13, %r5, 31;
	setp.eq.s32 	%p6, %r13, 0;
	@%p6 bra 	$L__BB0_9;

	mov.u32 	%r66, 32;
	sub.s32 	%r67, %r66, %r13;
	shr.u32 	%r68, %r155, %r67;
	shl.b32 	%r69, %r154, %r13;
	add.s32 	%r154, %r68, %r69;
	mul.wide.s32 	%rd32, %r10, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.local.u32 	%r70, [%rd33];
	shr.u32 	%r71, %r70, %r67;
	shl.b32 	%r72, %r155, %r13;
	add.s32 	%r155, %r71, %r72;

$L__BB0_9:
	and.b32  	%r73, %r4, -2147483648;
	shr.u32 	%r74, %r155, 30;
	shl.b32 	%r75, %r154, 2;
	or.b32  	%r76, %r74, %r75;
	shr.u32 	%r77, %r76, 31;
	shr.u32 	%r78, %r154, 30;
	add.s32 	%r79, %r77, %r78;
	neg.s32 	%r80, %r79;
	setp.eq.s32 	%p7, %r73, 0;
	selp.b32 	%r156, %r79, %r80, %p7;
	setp.ne.s32 	%p8, %r77, 0;
	xor.b32  	%r81, %r73, -2147483648;
	selp.b32 	%r82, %r81, %r73, %p8;
	selp.b32 	%r83, -1, 0, %p8;
	xor.b32  	%r84, %r76, %r83;
	shl.b32 	%r85, %r155, 2;
	xor.b32  	%r86, %r85, %r83;
	cvt.u64.u32 	%rd34, %r84;
	cvt.u64.u32 	%rd35, %r86;
	bfi.b64 	%rd36, %rd34, %rd35, 32, 32;
	cvt.rn.f64.s64 	%fd1, %rd36;
	mul.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f38, %fd2;
	setp.eq.s32 	%p9, %r82, 0;
	neg.f32 	%f39, %f38;
	selp.f32 	%f89, %f38, %f39, %p9;

$L__BB0_11:
	and.b32  	%r20, %r156, 1;
	setp.eq.s32 	%p10, %r20, 0;
	selp.f32 	%f8, %f89, 0f3F800000, %p10;
	mul.rn.f32 	%f9, %f89, %f89;
	mov.f32 	%f90, 0fB94D4153;
	@%p10 bra 	$L__BB0_13;

	mov.f32 	%f42, 0fBAB607ED;
	mov.f32 	%f43, 0f37CBAC00;
	fma.rn.f32 	%f90, %f43, %f9, %f42;

$L__BB0_13:
	selp.f32 	%f44, 0f3C0885E4, 0f3D2AAABB, %p10;
	fma.rn.f32 	%f45, %f90, %f9, %f44;
	selp.f32 	%f46, 0fBE2AAAA8, 0fBEFFFFFF, %p10;
	fma.rn.f32 	%f47, %f45, %f9, %f46;
	mov.f32 	%f48, 0f00000000;
	fma.rn.f32 	%f49, %f9, %f8, %f48;
	fma.rn.f32 	%f91, %f47, %f49, %f8;
	and.b32  	%r87, %r156, 2;
	setp.eq.s32 	%p12, %r87, 0;
	@%p12 bra 	$L__BB0_15;

	mov.f32 	%f51, 0fBF800000;
	fma.rn.f32 	%f91, %f91, %f51, %f48;

$L__BB0_15:
	mov.u32 	%r159, %r162;
	mov.f32 	%f92, %f95;
	@%p3 bra 	$L__BB0_23;

	setp.eq.f32 	%p14, %f4, 0f7F800000;
	@%p14 bra 	$L__BB0_22;
	bra.uni 	$L__BB0_17;

$L__BB0_22:
	mul.rn.f32 	%f92, %f96, %f48;
	mov.u32 	%r159, %r162;
	bra.uni 	$L__BB0_23;

$L__BB0_17:
	mov.b32 	%r21, %f96;
	bfe.u32 	%r88, %r21, 23, 8;
	add.s32 	%r22, %r88, -128;
	shl.b32 	%r89, %r21, 8;
	or.b32  	%r23, %r89, -2147483648;
	shr.u32 	%r24, %r22, 5;
	mov.u64 	%rd72, 0;
	mov.u64 	%rd71, %rd1;
	mov.u64 	%rd73, %rd72;

$L__BB0_18:
	.pragma "nounroll";
	shl.b64 	%rd39, %rd72, 2;
	mov.u64 	%rd40, __cudart_i2opi_f;
	add.s64 	%rd41, %rd40, %rd39;
	ld.global.nc.u32 	%r90, [%rd41];
	mad.wide.u32 	%rd42, %r90, %r23, %rd73;
	shr.u64 	%rd73, %rd42, 32;
	st.local.u32 	[%rd71], %rd42;
	cvt.u32.u64 	%r91, %rd72;
	add.s32 	%r92, %r91, 1;
	cvt.s64.s32 	%rd72, %r92;
	mul.wide.s32 	%rd43, %r92, 4;
	add.s64 	%rd71, %rd1, %rd43;
	setp.ne.s32 	%p15, %r92, 6;
	@%p15 bra 	$L__BB0_18;

	st.local.u32 	[%rd1+24], %rd73;
	mov.u32 	%r93, 4;
	sub.s32 	%r25, %r93, %r24;
	mov.u32 	%r94, 6;
	sub.s32 	%r95, %r94, %r24;
	mul.wide.s32 	%rd44, %r95, 4;
	add.s64 	%rd45, %rd1, %rd44;
	ld.local.u32 	%r157, [%rd45];
	ld.local.u32 	%r158, [%rd45+-4];
	and.b32  	%r28, %r22, 31;
	setp.eq.s32 	%p16, %r28, 0;
	@%p16 bra 	$L__BB0_21;

	mov.u32 	%r96, 32;
	sub.s32 	%r97, %r96, %r28;
	shr.u32 	%r98, %r158, %r97;
	shl.b32 	%r99, %r157, %r28;
	add.s32 	%r157, %r98, %r99;
	mul.wide.s32 	%rd46, %r25, 4;
	add.s64 	%rd47, %rd1, %rd46;
	ld.local.u32 	%r100, [%rd47];
	shr.u32 	%r101, %r100, %r97;
	shl.b32 	%r102, %r158, %r28;
	add.s32 	%r158, %r101, %r102;

$L__BB0_21:
	and.b32  	%r103, %r21, -2147483648;
	shr.u32 	%r104, %r158, 30;
	shl.b32 	%r105, %r157, 2;
	or.b32  	%r106, %r104, %r105;
	shr.u32 	%r107, %r106, 31;
	shr.u32 	%r108, %r157, 30;
	add.s32 	%r109, %r107, %r108;
	neg.s32 	%r110, %r109;
	setp.eq.s32 	%p17, %r103, 0;
	selp.b32 	%r159, %r109, %r110, %p17;
	setp.ne.s32 	%p18, %r107, 0;
	xor.b32  	%r111, %r103, -2147483648;
	selp.b32 	%r112, %r111, %r103, %p18;
	selp.b32 	%r113, -1, 0, %p18;
	xor.b32  	%r114, %r106, %r113;
	shl.b32 	%r115, %r158, 2;
	xor.b32  	%r116, %r115, %r113;
	cvt.u64.u32 	%rd48, %r114;
	cvt.u64.u32 	%rd49, %r116;
	bfi.b64 	%rd50, %rd48, %rd49, 32, 32;
	cvt.rn.f64.s64 	%fd3, %rd50;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f52, %fd4;
	setp.eq.s32 	%p19, %r112, 0;
	neg.f32 	%f53, %f52;
	selp.f32 	%f92, %f52, %f53, %p19;

$L__BB0_23:
	add.s32 	%r35, %r159, 1;
	and.b32  	%r36, %r35, 1;
	setp.eq.s32 	%p20, %r36, 0;
	selp.f32 	%f18, %f92, 0f3F800000, %p20;
	mul.rn.f32 	%f19, %f92, %f92;
	mov.f32 	%f93, 0fB94D4153;
	@%p20 bra 	$L__BB0_25;

	mov.f32 	%f56, 0fBAB607ED;
	mov.f32 	%f57, 0f37CBAC00;
	fma.rn.f32 	%f93, %f57, %f19, %f56;

$L__BB0_25:
	selp.f32 	%f58, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f59, %f93, %f19, %f58;
	selp.f32 	%f60, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f61, %f59, %f19, %f60;
	fma.rn.f32 	%f63, %f19, %f18, %f48;
	fma.rn.f32 	%f94, %f61, %f63, %f18;
	and.b32  	%r117, %r35, 2;
	setp.eq.s32 	%p22, %r117, 0;
	@%p22 bra 	$L__BB0_27;

	mov.f32 	%f65, 0fBF800000;
	fma.rn.f32 	%f94, %f94, %f65, %f48;

$L__BB0_27:
	mul.f32 	%f25, %f91, %f94;
	@%p3 bra 	$L__BB0_35;

	setp.eq.f32 	%p24, %f4, 0f7F800000;
	@%p24 bra 	$L__BB0_34;
	bra.uni 	$L__BB0_29;

$L__BB0_34:
	mul.rn.f32 	%f95, %f96, %f48;
	bra.uni 	$L__BB0_35;

$L__BB0_29:
	mov.b32 	%r37, %f96;
	bfe.u32 	%r118, %r37, 23, 8;
	add.s32 	%r38, %r118, -128;
	shl.b32 	%r119, %r37, 8;
	or.b32  	%r39, %r119, -2147483648;
	shr.u32 	%r40, %r38, 5;
	mov.u64 	%rd75, 0;
	mov.u64 	%rd74, %rd1;
	mov.u64 	%rd76, %rd75;

$L__BB0_30:
	.pragma "nounroll";
	shl.b64 	%rd53, %rd75, 2;
	mov.u64 	%rd54, __cudart_i2opi_f;
	add.s64 	%rd55, %rd54, %rd53;
	ld.global.nc.u32 	%r120, [%rd55];
	mad.wide.u32 	%rd56, %r120, %r39, %rd76;
	shr.u64 	%rd76, %rd56, 32;
	st.local.u32 	[%rd74], %rd56;
	cvt.u32.u64 	%r121, %rd75;
	add.s32 	%r122, %r121, 1;
	cvt.s64.s32 	%rd75, %r122;
	mul.wide.s32 	%rd57, %r122, 4;
	add.s64 	%rd74, %rd1, %rd57;
	setp.ne.s32 	%p25, %r122, 6;
	@%p25 bra 	$L__BB0_30;

	st.local.u32 	[%rd1+24], %rd76;
	mov.u32 	%r123, 4;
	sub.s32 	%r41, %r123, %r40;
	mov.u32 	%r124, 6;
	sub.s32 	%r125, %r124, %r40;
	mul.wide.s32 	%rd58, %r125, 4;
	add.s64 	%rd59, %rd1, %rd58;
	ld.local.u32 	%r160, [%rd59];
	ld.local.u32 	%r161, [%rd59+-4];
	and.b32  	%r44, %r38, 31;
	setp.eq.s32 	%p26, %r44, 0;
	@%p26 bra 	$L__BB0_33;

	mov.u32 	%r126, 32;
	sub.s32 	%r127, %r126, %r44;
	shr.u32 	%r128, %r161, %r127;
	shl.b32 	%r129, %r160, %r44;
	add.s32 	%r160, %r128, %r129;
	mul.wide.s32 	%rd60, %r41, 4;
	add.s64 	%rd61, %rd1, %rd60;
	ld.local.u32 	%r130, [%rd61];
	shr.u32 	%r131, %r130, %r127;
	shl.b32 	%r132, %r161, %r44;
	add.s32 	%r161, %r131, %r132;

$L__BB0_33:
	and.b32  	%r133, %r37, -2147483648;
	shr.u32 	%r134, %r161, 30;
	shl.b32 	%r135, %r160, 2;
	or.b32  	%r136, %r134, %r135;
	shr.u32 	%r137, %r136, 31;
	shr.u32 	%r138, %r160, 30;
	add.s32 	%r139, %r137, %r138;
	neg.s32 	%r140, %r139;
	setp.eq.s32 	%p27, %r133, 0;
	selp.b32 	%r162, %r139, %r140, %p27;
	setp.ne.s32 	%p28, %r137, 0;
	xor.b32  	%r141, %r133, -2147483648;
	selp.b32 	%r142, %r141, %r133, %p28;
	selp.b32 	%r143, -1, 0, %p28;
	xor.b32  	%r144, %r136, %r143;
	shl.b32 	%r145, %r161, 2;
	xor.b32  	%r146, %r145, %r143;
	cvt.u64.u32 	%rd62, %r144;
	cvt.u64.u32 	%rd63, %r146;
	bfi.b64 	%rd64, %rd62, %rd63, 32, 32;
	cvt.rn.f64.s64 	%fd5, %rd64;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f66, %fd6;
	setp.eq.s32 	%p29, %r142, 0;
	neg.f32 	%f67, %f66;
	selp.f32 	%f95, %f66, %f67, %p29;

$L__BB0_35:
	mul.f32 	%f69, %f95, %f95;
	mov.f32 	%f70, 0f3B560000;
	mov.f32 	%f71, 0f3C190000;
	fma.rn.f32 	%f72, %f71, %f69, %f70;
	mov.f32 	%f73, 0f3CC70000;
	fma.rn.f32 	%f74, %f72, %f69, %f73;
	mov.f32 	%f75, 0f3D5B0000;
	fma.rn.f32 	%f76, %f74, %f69, %f75;
	mov.f32 	%f77, 0f3E089438;
	fma.rn.f32 	%f78, %f76, %f69, %f77;
	mov.f32 	%f79, 0f3EAAAA88;
	fma.rn.f32 	%f80, %f78, %f69, %f79;
	mul.rn.f32 	%f81, %f69, %f95;
	fma.rn.f32 	%f82, %f80, %f81, %f95;
	abs.f32 	%f83, %f95;
	setp.eq.f32 	%p30, %f83, 0f3A00B43C;
	selp.f32 	%f84, %f95, %f82, %p30;
	and.b32  	%r147, %r162, 1;
	setp.eq.b32 	%p31, %r147, 1;
	rcp.approx.ftz.f32 	%f85, %f84;
	neg.f32 	%f86, %f85;
	selp.f32 	%f87, %f86, %f84, %p31;
	add.f32 	%f96, %f25, %f87;
	add.s32 	%r152, %r152, 1;
	setp.lt.s32 	%p32, %r152, %r52;
	@%p32 bra 	$L__BB0_3;

$L__BB0_36:
	st.global.f32 	[%rd26], %f96;

$L__BB0_37:
	ret;

}

